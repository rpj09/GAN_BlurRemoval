{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"private_outputs":true,"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":10001027,"sourceType":"datasetVersion","datasetId":6155879},{"sourceId":10001547,"sourceType":"datasetVersion","datasetId":6156256}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GAN_BlurRemoval\n\nCurrently only one picture as input allowed.\n\nMy coalb fork: [rpj09/GAN_BlurRemoval](https://github.com/rpj09/GAN_BlurRemoval.git)\n\nSimple tutoiral:\nPlace ```input.png``` in kaggle input as dataset.","metadata":{"id":"o1Cyaut6utnv"}},{"cell_type":"code","source":"# check gpu\n!nvidia-smi","metadata":{"id":"PUTg2s-by8si","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:32:20.853846Z","iopub.execute_input":"2024-11-24T15:32:20.854441Z","iopub.status.idle":"2024-11-24T15:32:22.055496Z","shell.execute_reply.started":"2024-11-24T15:32:20.854408Z","shell.execute_reply":"2024-11-24T15:32:22.054461Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: nvidia-smi: command not found\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Deblur with InceptionResNet-v2","metadata":{"id":"FQbbcY7Ouzd_"}},{"cell_type":"code","source":"#@title Installing and downloading model\n%cd /kaggle/working/\n!git clone https://github.com/rpj09/GAN_BlurRemoval.git\n!pip install fire\n!pip install pretrainedmodels\n!pip install gdown\n%cd /kaggle/working/GAN_BlurRemoval/models\n!gdown --id 1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR","metadata":{"id":"4G9sFBtrnmZz","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:15:07.372770Z","iopub.execute_input":"2024-11-24T16:15:07.373499Z","iopub.status.idle":"2024-11-24T16:15:51.568294Z","shell.execute_reply.started":"2024-11-24T16:15:07.373466Z","shell.execute_reply":"2024-11-24T16:15:51.567431Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'Colab-DeblurGANv2'...\nremote: Enumerating objects: 835, done.\u001b[K\nremote: Counting objects: 100% (227/227), done.\u001b[K\nremote: Compressing objects: 100% (110/110), done.\u001b[K\nremote: Total 835 (delta 118), reused 117 (delta 117), pack-reused 608 (from 1)\u001b[K\nReceiving objects: 100% (835/835), 61.79 MiB | 19.13 MiB/s, done.\nResolving deltas: 100% (442/442), done.\nCollecting fire\n  Downloading fire-0.7.0.tar.gz (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire) (2.4.0)\nBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114248 sha256=8b099142bbdcdcf8bde7564768e0ca993cec35ea0fcf5dca33e837c3a8a6d1ab\n  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\nSuccessfully built fire\nInstalling collected packages: fire\nSuccessfully installed fire-0.7.0\nCollecting pretrainedmodels\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (0.19.0)\nCollecting munch (from pretrainedmodels)\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pretrainedmodels) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pretrainedmodels) (1.3.0)\nDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: pretrainedmodels\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=6af2783b0337e7e98d65f9741f9f721aee560be71ef7a6c43e65902dcb293d47\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built pretrainedmodels\nInstalling collected packages: munch, pretrainedmodels\nSuccessfully installed munch-4.0.0 pretrainedmodels-0.7.4\nCollecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n/kaggle/working/Colab-DeblurGANv2/models\n/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR\nFrom (redirected): https://drive.google.com/uc?id=1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR&confirm=t&uuid=02531f78-b00e-4d3a-a05c-a48f2ec993ee\nTo: /kaggle/working/Colab-DeblurGANv2/models/fpn_inception.h5\n100%|████████████████████████████████████████| 244M/244M [00:05<00:00, 47.6MB/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n \n# Function to Get the current\n# working directory\ndef current_path():\n    print(\"Current working directory before\")\n    print(os.getcwd())\n    print()\n \n \n# Driver's code\n# Printing CWD before\ncurrent_path()\n \n# Changing the CWD\nos.chdir('/kaggle/working/GAN_BlurRemoval/')\n \n# Printing CWD after\ncurrent_path()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:17:20.582510Z","iopub.execute_input":"2024-11-24T16:17:20.583352Z","iopub.status.idle":"2024-11-24T16:17:20.588379Z","shell.execute_reply.started":"2024-11-24T16:17:20.583318Z","shell.execute_reply":"2024-11-24T16:17:20.587491Z"}},"outputs":[{"name":"stdout","text":"Current working directory before\n/kaggle/working/Colab-DeblurGANv2/models\n\nCurrent working directory before\n/kaggle/working/Colab-DeblurGANv2\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:17:27.059047Z","iopub.execute_input":"2024-11-24T16:17:27.059638Z","iopub.status.idle":"2024-11-24T16:17:28.049494Z","shell.execute_reply.started":"2024-11-24T16:17:27.059603Z","shell.execute_reply":"2024-11-24T16:17:28.048432Z"}},"outputs":[{"name":"stdout","text":"Colab-DeblurGANv2.ipynb  config\t\t    predict.py\t      test_dataset.py\nLICENSE\t\t\t dataset.py\t    requirements.txt  test_metrics.py\nREADME.md\t\t doc_images\t    schedulers.py     train.py\nadversarial_trainer.py\t metric_counter.py  test.sh\t      util\naug.py\t\t\t models\t\t    test_aug.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%writefile /kaggle/working/GAN_BlurRemoval/predict.py\n\n\nimport os\nfrom glob import glob\nfrom typing import Optional\n\nimport cv2\nimport numpy as np\nimport torch\nimport yaml\nfrom fire import Fire\nfrom tqdm import tqdm\n\nimport ssl\nimport urllib.request\n\n# Disable SSL certificate verification\nssl._create_default_https_context = ssl._create_unverified_context\n\nfrom aug import get_normalize\nfrom models.networks import get_generator\n\n\nclass Predictor:\n    def __init__(self, weights_path: str, model_name: str = ''):\n        with open('config/config.yaml') as cfg:\n            config = yaml.load(cfg, Loader=yaml.FullLoader)\n        model = get_generator(model_name or config['model'])\n        model.load_state_dict(torch.load(weights_path)['model'])\n        self.model = model.cuda()\n        self.model.train(True)\n        # GAN inference should be in train mode to use actual stats in norm layers,\n        # it's not a bug\n        self.normalize_fn = get_normalize()\n\n    @staticmethod\n    def _array_to_batch(x):\n        x = np.transpose(x, (2, 0, 1))\n        x = np.expand_dims(x, 0)\n        return torch.from_numpy(x)\n\n    def _preprocess(self, x: np.ndarray, mask: Optional[np.ndarray]):\n        x, _ = self.normalize_fn(x, x)\n        if mask is None:\n            mask = np.ones_like(x, dtype=np.float32)\n        else:\n            mask = np.round(mask.astype('float32') / 255)\n\n        h, w, _ = x.shape\n        block_size = 32\n        min_height = (h // block_size + 1) * block_size\n        min_width = (w // block_size + 1) * block_size\n\n        pad_params = {'mode': 'constant',\n                      'constant_values': 0,\n                      'pad_width': ((0, min_height - h), (0, min_width - w), (0, 0))\n                      }\n        x = np.pad(x, **pad_params)\n        mask = np.pad(mask, **pad_params)\n\n        return map(self._array_to_batch, (x, mask)), h, w\n\n    @staticmethod\n    def _postprocess(x: torch.Tensor) -> np.ndarray:\n        x, = x\n        x = x.detach().cpu().float().numpy()\n        x = (np.transpose(x, (1, 2, 0)) + 1) / 2.0 * 255.0\n        return x.astype('uint8')\n\n    def __call__(self, img: np.ndarray, mask: Optional[np.ndarray], ignore_mask=True) -> np.ndarray:\n        (img, mask), h, w = self._preprocess(img, mask)\n        with torch.no_grad():\n            inputs = [img.cuda()]\n            if not ignore_mask:\n                inputs += [mask]\n            pred = self.model(*inputs)\n        return self._postprocess(pred)[:h, :w, :]\n\ndef process_video(pairs, predictor, output_dir):\n    for video_filepath, mask in tqdm(pairs):\n        video_filename = os.path.basename(video_filepath)\n        output_filepath = os.path.join(output_dir, os.path.splitext(video_filename)[0]+'_deblur.mp4')\n        video_in = cv2.VideoCapture(video_filepath)\n        fps = video_in.get(cv2.CAP_PROP_FPS)\n        width = int(video_in.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(video_in.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        total_frame_num = int(video_in.get(cv2.CAP_PROP_FRAME_COUNT))\n        video_out = cv2.VideoWriter(output_filepath, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))\n        tqdm.write(f'process {video_filepath} to {output_filepath}, {fps}fps, resolution: {width}x{height}')\n        for frame_num in tqdm(range(total_frame_num), desc=video_filename):\n            res, img = video_in.read()\n            if not res:\n                break\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            pred = predictor(img, mask)\n            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n            video_out.write(pred)\n\ndef main(img_pattern: str,\n         mask_pattern: Optional[str] = None,\n         weights_path='/kaggle/working/GAN_BlurRemoval/models/fpn_inception.h5',\n         out_dir='submit/',\n         side_by_side: bool = False,\n         video: bool = False):\n    def sorted_glob(pattern):\n        return sorted(glob(pattern))\n\n    imgs = sorted_glob(img_pattern)\n    masks = sorted_glob(mask_pattern) if mask_pattern is not None else [None for _ in imgs]\n    pairs = zip(imgs, masks)\n    names = sorted([os.path.basename(x) for x in glob(img_pattern)])\n    predictor = Predictor(weights_path=weights_path)\n\n    os.makedirs(out_dir, exist_ok=True)\n    if not video:\n        for name, pair in tqdm(zip(names, pairs), total=len(names)):\n            f_img, f_mask = pair\n            img, mask = map(cv2.imread, (f_img, f_mask))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n            pred = predictor(img, mask)\n            if side_by_side:\n                pred = np.hstack((img, pred))\n            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(os.path.join(out_dir, name),\n                        pred)\n    else:\n        process_video(pairs, predictor, out_dir)\n\n\nif __name__ == '__main__':\n    Fire(main)","metadata":{"id":"PW6au4DWuJkV","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:17:32.170553Z","iopub.execute_input":"2024-11-24T16:17:32.170924Z","iopub.status.idle":"2024-11-24T16:17:32.179792Z","shell.execute_reply.started":"2024-11-24T16:17:32.170889Z","shell.execute_reply":"2024-11-24T16:17:32.178806Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/Colab-DeblurGANv2/predict.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:14:06.319166Z","iopub.execute_input":"2024-11-24T17:14:06.319961Z","iopub.status.idle":"2024-11-24T17:14:07.318827Z","shell.execute_reply.started":"2024-11-24T17:14:06.319928Z","shell.execute_reply":"2024-11-24T17:14:07.317709Z"}},"outputs":[{"name":"stdout","text":"Colab-DeblurGANv2.ipynb  config\t\t    requirements.txt  test_metrics.py\nLICENSE\t\t\t dataset.py\t    schedulers.py     train.py\nREADME.md\t\t doc_images\t    submit\t      util\n__pycache__\t\t metric_counter.py  test.sh\nadversarial_trainer.py\t models\t\t    test_aug.py\naug.py\t\t\t predict.py\t    test_dataset.py\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"%%writefile ./config/config.yaml\n\nproject: deblur_gan\nexperiment_desc: fpn_improved\n\ntrain:\n  files_a: &FILES_A /datasets/my_dataset/**/*.jpg\n  files_b: *FILES_A\n  size: &SIZE 512  # Increased from 256\n  crop: random\n  preload: &PRELOAD false\n  preload_size: &PRELOAD_SIZE 0\n  bounds: [0, .9]\n  scope: geometric\n  corrupt: &CORRUPT\n    - name: cutout\n      prob: 0.7  # Increased corruption probability\n      num_holes: 5  # Increased number of holes\n      max_h_size: 50  # Increased max hole size\n      max_w_size: 50\n    - name: jpeg\n      quality_lower: 50  # Wider quality range for stronger corruption\n      quality_upper: 90\n    - name: motion_blur\n      prob: 0.8  # Increased probability\n      kernel_size: 5  # Added kernel size for stronger motion blur\n    - name: median_blur\n      prob: 0.8\n      kernel_size: 5\n    - name: gamma\n      gamma_lower: 0.5  # Enhanced gamma adjustments\n      gamma_upper: 2.0\n    - name: sharpen\n    - name: rgb_shift\n    - name: hsv_shift\n\nval:\n  files_a: *FILES_A\n  files_b: *FILES_A\n  size: *SIZE\n  scope: geometric\n  crop: center\n  preload: *PRELOAD\n  preload_size: *PRELOAD_SIZE\n  bounds: [.9, 1]\n  corrupt: *CORRUPT\n\nphase: train\nwarmup_num: 3\nmodel:\n  g_name: fpn_inception\n  blocks: 16  # Increased number of blocks\n  d_name: patch_gan  # More robust discriminator\n  d_layers: 4\n  content_loss: perceptual\n  adv_lambda: 0.002  # Increased GAN contribution\n  disc_loss: hinge  # Updated discriminator loss\n  learn_residual: True\n  norm_layer: instance\n  dropout: True\n\nnum_epochs: 300  # Increased epochs for stronger training\ntrain_batches_per_epoch: 1500  # More batches per epoch\nval_batches_per_epoch: 200\nbatch_size: 4  # Larger batch size\nimage_size: [512, 512]\n\noptimizer:\n  name: adam\n  lr: 0.00005  # Lowered learning rate for stability\nscheduler:\n  name: linear\n  start_epoch: 50\n  min_lr: 0.0000001\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:21:52.219749Z","iopub.execute_input":"2024-11-24T17:21:52.220129Z","iopub.status.idle":"2024-11-24T17:21:52.227524Z","shell.execute_reply.started":"2024-11-24T17:21:52.220094Z","shell.execute_reply":"2024-11-24T17:21:52.226624Z"}},"outputs":[{"name":"stdout","text":"Overwriting ./config/config.yaml\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"#@title Downloading model from my Google Drive (Very fast download)\n!mkdir /root/\n!mkdir /root/.cache/\n!mkdir /root/.cache/torch/\n!mkdir /root/.cache/torch/checkpoints/\n%cd /root/.cache/torch/checkpoints/\n!gdown --id 1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X","metadata":{"id":"lImGMorGKGTd","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:17:53.671866Z","iopub.execute_input":"2024-11-24T16:17:53.672436Z","iopub.status.idle":"2024-11-24T16:18:06.468401Z","shell.execute_reply.started":"2024-11-24T16:17:53.672404Z","shell.execute_reply":"2024-11-24T16:18:06.467495Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory '/root/': File exists\nmkdir: cannot create directory '/root/.cache/': File exists\n/root/.cache/torch/checkpoints\n/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X\nFrom (redirected): https://drive.google.com/uc?id=1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X&confirm=t&uuid=481e961f-a754-46fb-aff7-f1237957a177\nTo: /root/.cache/torch/checkpoints/inceptionresnetv2-520b38e4.pth\n100%|████████████████████████████████████████| 224M/224M [00:03<00:00, 71.6MB/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:22:03.736601Z","iopub.execute_input":"2024-11-24T16:22:03.736964Z","iopub.status.idle":"2024-11-24T16:22:04.748296Z","shell.execute_reply.started":"2024-11-24T16:22:03.736933Z","shell.execute_reply":"2024-11-24T16:22:04.747243Z"}},"outputs":[{"name":"stdout","text":"/root/.cache/torch/checkpoints\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Install required dependencies\n!pip install torchsummary\n\n# Run deblurring\n%cd /kaggle/working/GAN_BlurRemoval\n!python predict.py \"/kaggle/input/input-png/input.jpeg\"\n\n# Check if the output file exists, remove it, and copy the new one\noutput_path = \"/kaggle/working/GAN_BlurRemoval/submit/input.jpeg\"\ndestination_path = \"/kaggle/working/output.jpeg\"\n\nimport os\nif os.path.exists(destination_path):\n    os.remove(destination_path)  # Remove the existing output file\n    print(f\"Existing file at '{destination_path}' has been removed.\")\n\nif os.path.exists(output_path):\n    !cp {output_path} {destination_path}\n    print(f\"Deblurred image saved as '{destination_path}'\")\nelse:\n    print(f\"Output file '{output_path}' not found. Check the deblurring process for errors.\")\n","metadata":{"id":"9kImTgk3pncs","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:21:58.149637Z","iopub.execute_input":"2024-11-24T17:21:58.150209Z","iopub.status.idle":"2024-11-24T17:22:15.584059Z","shell.execute_reply.started":"2024-11-24T17:21:58.150177Z","shell.execute_reply":"2024-11-24T17:22:15.582968Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n/kaggle/working/Colab-DeblurGANv2\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n/kaggle/working/Colab-DeblurGANv2/predict.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(weights_path)['model'])\n  0%|                                                     | 0/1 [00:00<?, ?it/s][ WARN:0@5.762] global loadsave.cpp:241 findDecoder imread_(''): can't open/read file: check file path/integrity\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:164: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map3 = self.td1(lateral3 + nn.functional.upsample(map4, scale_factor=2, mode=\"nearest\"))\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:165: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map2 = self.td2(F.pad(lateral2, pad, \"reflect\") + nn.functional.upsample(map3, scale_factor=2, mode=\"nearest\"))\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:166: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map1 = self.td3(lateral1 + nn.functional.upsample(map2, scale_factor=2, mode=\"nearest\"))\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:68: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map4 = nn.functional.upsample(self.head4(map4), scale_factor=8, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:69: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map3 = nn.functional.upsample(self.head3(map3), scale_factor=4, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:70: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map2 = nn.functional.upsample(self.head2(map2), scale_factor=2, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:71: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map1 = nn.functional.upsample(self.head1(map1), scale_factor=1, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:74: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_inception.py:76: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\nExisting file at '/kaggle/working/output.jpeg' has been removed.\nDeblurred image saved as '/kaggle/working/output.jpeg'\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Read the output image\ndeblurred_image = cv2.imread('/kaggle/working/output.jpeg')\n\n# Apply sharpening kernel\nkernel = np.array([[0, -1, 0], \n                   [-1, 5,-1], \n                   [0, -1, 0]])\nsharpened = cv2.filter2D(deblurred_image, -1, kernel)\n\n# Save the sharpened image\ncv2.imwrite('/kaggle/working/sharpened_output.jpeg', sharpened)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:22:30.429156Z","iopub.execute_input":"2024-11-24T17:22:30.429518Z","iopub.status.idle":"2024-11-24T17:22:30.447536Z","shell.execute_reply.started":"2024-11-24T17:22:30.429483Z","shell.execute_reply":"2024-11-24T17:22:30.446732Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"# Deblur with MobileNet","metadata":{"id":"3Qucha-Su4J7"}},{"cell_type":"code","source":"#@title Installing and downloading models\n%cd /kaggle/working/\n!git clone https://github.com/rpj09/GAN_BlurRemoval.git\n!pip install fire\n!pip install pretrainedmodels\n!pip install gdown\n%cd /kaggle/working/GAN_BlurRemoval/models\n!gdown --id 1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR\n!wget --no-check-certificate http://sceneparsing.csail.mit.edu/model/pretrained_resnet/mobilenet_v2.pth.tar\n!gdown --id 1JhnT4BBeKBBSLqTo6UsJ13HeBXevarrU","metadata":{"id":"DZmeIqZ8u8YL","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:02:45.549703Z","iopub.execute_input":"2024-11-24T19:02:45.550582Z","iopub.status.idle":"2024-11-24T19:03:38.723287Z","shell.execute_reply.started":"2024-11-24T19:02:45.550546Z","shell.execute_reply":"2024-11-24T19:03:38.722185Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'Colab-DeblurGANv2'...\nremote: Enumerating objects: 835, done.\u001b[K\nremote: Counting objects: 100% (227/227), done.\u001b[K\nremote: Compressing objects: 100% (110/110), done.\u001b[K\nremote: Total 835 (delta 118), reused 117 (delta 117), pack-reused 608 (from 1)\u001b[K\nReceiving objects: 100% (835/835), 61.79 MiB | 18.83 MiB/s, done.\nResolving deltas: 100% (442/442), done.\nRequirement already satisfied: fire in /opt/conda/lib/python3.10/site-packages (0.7.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire) (2.4.0)\nRequirement already satisfied: pretrainedmodels in /opt/conda/lib/python3.10/site-packages (0.7.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (0.19.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (4.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pretrainedmodels) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pretrainedmodels) (1.3.0)\nRequirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n/kaggle/working/Colab-DeblurGANv2/models\n/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR\nFrom (redirected): https://drive.google.com/uc?id=1UXcsRVW-6KF23_TNzxw-xC0SzaMfXOaR&confirm=t&uuid=9eadaf28-aa1b-45e7-b456-39dcd9729807\nTo: /kaggle/working/Colab-DeblurGANv2/models/fpn_inception.h5\n100%|████████████████████████████████████████| 244M/244M [00:04<00:00, 53.2MB/s]\n--2024-11-24 19:03:26--  http://sceneparsing.csail.mit.edu/model/pretrained_resnet/mobilenet_v2.pth.tar\nResolving sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu)... 128.30.100.223\nConnecting to sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu)|128.30.100.223|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14205652 (14M) [application/x-tar]\nSaving to: 'mobilenet_v2.pth.tar'\n\nmobilenet_v2.pth.ta 100%[===================>]  13.55M  3.66MB/s    in 3.7s    \n\n2024-11-24 19:03:30 (3.66 MB/s) - 'mobilenet_v2.pth.tar' saved [14205652/14205652]\n\n/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1JhnT4BBeKBBSLqTo6UsJ13HeBXevarrU\nTo: /kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.h5\n100%|██████████████████████████████████████| 13.5M/13.5M [00:00<00:00, 39.6MB/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!ls\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:02:31.856328Z","iopub.execute_input":"2024-11-24T19:02:31.856986Z","iopub.status.idle":"2024-11-24T19:02:32.846342Z","shell.execute_reply.started":"2024-11-24T19:02:31.856955Z","shell.execute_reply":"2024-11-24T19:02:32.845271Z"}},"outputs":[{"name":"stdout","text":"fpn_inception.h5  fpn_mobilenet.h5  mobilenet_v2.pth.tar\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\n \n# Function to Get the current\n# working directory\ndef current_path():\n    print(\"Current working directory before\")\n    print(os.getcwd())\n    print()\n \n \n# Driver's code\n# Printing CWD before\ncurrent_path()\n \n# Changing the CWD\nos.chdir('/kaggle/working/GAN_BlurRemoval/')\n \n# Printing CWD after\ncurrent_path()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:04:26.671373Z","iopub.execute_input":"2024-11-24T19:04:26.672173Z","iopub.status.idle":"2024-11-24T19:04:26.677168Z","shell.execute_reply.started":"2024-11-24T19:04:26.672139Z","shell.execute_reply":"2024-11-24T19:04:26.676324Z"}},"outputs":[{"name":"stdout","text":"Current working directory before\n/kaggle/working/Colab-DeblurGANv2\n\nCurrent working directory before\n/kaggle/working/Colab-DeblurGANv2\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:05:07.065925Z","iopub.execute_input":"2024-11-24T19:05:07.066653Z","iopub.status.idle":"2024-11-24T19:05:08.071637Z","shell.execute_reply.started":"2024-11-24T19:05:07.066597Z","shell.execute_reply":"2024-11-24T19:05:08.070791Z"}},"outputs":[{"name":"stdout","text":"Colab-DeblurGANv2.ipynb  config\t\t    predict.py\t      test_dataset.py\nLICENSE\t\t\t dataset.py\t    requirements.txt  test_metrics.py\nREADME.md\t\t doc_images\t    schedulers.py     train.py\nadversarial_trainer.py\t metric_counter.py  test.sh\t      util\naug.py\t\t\t models\t\t    test_aug.py\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"%%writefile ./config/config.yaml\n\nproject: deblur_gan\nexperiment_desc: fpn\n\ntrain:\n  files_a: &FILES_A /datasets/my_dataset/**/*.jpg\n  files_b: *FILES_A\n  size: &SIZE 256\n  crop: random\n  preload: &PRELOAD false\n  preload_size: &PRELOAD_SIZE 0\n  bounds: [0, .9]\n  scope: geometric\n  corrupt: &CORRUPT\n    - name: cutout\n      prob: 0.5\n      num_holes: 3\n      max_h_size: 25\n      max_w_size: 25\n    - name: jpeg\n      quality_lower: 70\n      quality_upper: 90\n    - name: motion_blur\n    - name: median_blur\n    - name: gamma\n    - name: rgb_shift\n    - name: hsv_shift\n    - name: sharpen\n\nval:\n  files_a: *FILES_A\n  files_b: *FILES_A\n  size: *SIZE\n  scope: geometric\n  crop: center\n  preload: *PRELOAD\n  preload_size: *PRELOAD_SIZE\n  bounds: [.9, 1]\n  corrupt: *CORRUPT\n\nphase: train\nwarmup_num: 3\nmodel:\n  g_name: fpn_mobilenet\n  blocks: 9\n  d_name: double_gan # may be no_gan, patch_gan, double_gan, multi_scale\n  d_layers: 3\n  content_loss: perceptual\n  adv_lambda: 0.001\n  disc_loss: wgan-gp\n  learn_residual: True\n  norm_layer: instance\n  dropout: True\n\nnum_epochs: 200\ntrain_batches_per_epoch: 1000\nval_batches_per_epoch: 100\nbatch_size: 1\nimage_size: [256, 256]\n\noptimizer:\n  name: adam\n  lr: 0.0001\nscheduler:\n  name: linear\n  start_epoch: 50\n  min_lr: 0.0000001","metadata":{"id":"4-xu__FIp6Jz","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:05:26.875648Z","iopub.execute_input":"2024-11-24T19:05:26.876094Z","iopub.status.idle":"2024-11-24T19:05:26.884632Z","shell.execute_reply.started":"2024-11-24T19:05:26.876052Z","shell.execute_reply":"2024-11-24T19:05:26.883691Z"}},"outputs":[{"name":"stdout","text":"Overwriting ./config/config.yaml\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"%%writefile /kaggle/working/GAN_BlurRemoval/predict.py\nimport os\nfrom glob import glob\nfrom typing import Optional\n\nimport cv2\nimport numpy as np\nimport torch\nimport yaml\nfrom fire import Fire\nfrom tqdm import tqdm\n\nimport ssl\nimport urllib.request\n\n# Disable SSL certificate verification\nssl._create_default_https_context = ssl._create_unverified_context\n\nfrom aug import get_normalize\nfrom models.networks import get_generator\n\n\nclass Predictor:\n    def __init__(self, weights_path: str, model_name: str = ''):\n        with open('config/config.yaml') as cfg:\n            config = yaml.load(cfg, Loader=yaml.FullLoader)\n        model = get_generator(model_name or config['model'])\n        model.load_state_dict(torch.load(weights_path)['model'])\n        self.model = model.cuda()\n        self.model.train(True)\n        # GAN inference should be in train mode to use actual stats in norm layers,\n        # it's not a bug\n        self.normalize_fn = get_normalize()\n\n    @staticmethod\n    def _array_to_batch(x):\n        x = np.transpose(x, (2, 0, 1))\n        x = np.expand_dims(x, 0)\n        return torch.from_numpy(x)\n\n    def _preprocess(self, x: np.ndarray, mask: Optional[np.ndarray]):\n        x, _ = self.normalize_fn(x, x)\n        if mask is None:\n            mask = np.ones_like(x, dtype=np.float32)\n        else:\n            mask = np.round(mask.astype('float32') / 255)\n\n        h, w, _ = x.shape\n        block_size = 32\n        min_height = (h // block_size + 1) * block_size\n        min_width = (w // block_size + 1) * block_size\n\n        pad_params = {'mode': 'constant',\n                      'constant_values': 0,\n                      'pad_width': ((0, min_height - h), (0, min_width - w), (0, 0))\n                      }\n        x = np.pad(x, **pad_params)\n        mask = np.pad(mask, **pad_params)\n\n        return map(self._array_to_batch, (x, mask)), h, w\n\n    @staticmethod\n    def _postprocess(x: torch.Tensor) -> np.ndarray:\n        x, = x\n        x = x.detach().cpu().float().numpy()\n        x = (np.transpose(x, (1, 2, 0)) + 1) / 2.0 * 255.0\n        return x.astype('uint8')\n\n    def __call__(self, img: np.ndarray, mask: Optional[np.ndarray], ignore_mask=True) -> np.ndarray:\n        (img, mask), h, w = self._preprocess(img, mask)\n        with torch.no_grad():\n            inputs = [img.cuda()]\n            if not ignore_mask:\n                inputs += [mask]\n            pred = self.model(*inputs)\n        return self._postprocess(pred)[:h, :w, :]\n\ndef process_video(pairs, predictor, output_dir):\n    for video_filepath, mask in tqdm(pairs):\n        video_filename = os.path.basename(video_filepath)\n        output_filepath = os.path.join(output_dir, os.path.splitext(video_filename)[0]+'_deblur.mp4')\n        video_in = cv2.VideoCapture(video_filepath)\n        fps = video_in.get(cv2.CAP_PROP_FPS)\n        width = int(video_in.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(video_in.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        total_frame_num = int(video_in.get(cv2.CAP_PROP_FRAME_COUNT))\n        video_out = cv2.VideoWriter(output_filepath, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))\n        tqdm.write(f'process {video_filepath} to {output_filepath}, {fps}fps, resolution: {width}x{height}')\n        for frame_num in tqdm(range(total_frame_num), desc=video_filename):\n            res, img = video_in.read()\n            if not res:\n                break\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            pred = predictor(img, mask)\n            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n            video_out.write(pred)\n\ndef main(img_pattern: str,\n         mask_pattern: Optional[str] = None,\n         weights_path='/kaggle/working/GAN_BlurRemoval/models/fpn_mobilenet.h5',\n         out_dir='submit/',\n         side_by_side: bool = False,\n         video: bool = False):\n    def sorted_glob(pattern):\n        return sorted(glob(pattern))\n\n    imgs = sorted_glob(img_pattern)\n    masks = sorted_glob(mask_pattern) if mask_pattern is not None else [None for _ in imgs]\n    pairs = zip(imgs, masks)\n    names = sorted([os.path.basename(x) for x in glob(img_pattern)])\n    predictor = Predictor(weights_path=weights_path)\n\n    os.makedirs(out_dir, exist_ok=True)\n    if not video:\n        for name, pair in tqdm(zip(names, pairs), total=len(names)):\n            f_img, f_mask = pair\n            img, mask = map(cv2.imread, (f_img, f_mask))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n            pred = predictor(img, mask)\n            if side_by_side:\n                pred = np.hstack((img, pred))\n            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(os.path.join(out_dir, name),\n                        pred)\n    else:\n        process_video(pairs, predictor, out_dir)\n\n\nif __name__ == '__main__':\n    Fire(main)","metadata":{"id":"cOarMZ1Kvjgv","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:10:06.590608Z","iopub.execute_input":"2024-11-24T19:10:06.590957Z","iopub.status.idle":"2024-11-24T19:10:06.598739Z","shell.execute_reply.started":"2024-11-24T19:10:06.590929Z","shell.execute_reply":"2024-11-24T19:10:06.597924Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/Colab-DeblurGANv2/predict.py\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"%%writefile /kaggle/working/GAN_BlurRemoval/models/fpn_mobilenet.py\nimport torch\nimport torch.nn as nn\nfrom models.mobilenet_v2 import MobileNetV2\n\nclass FPNHead(nn.Module):\n    def __init__(self, num_in, num_mid, num_out):\n        super().__init__()\n\n        self.block0 = nn.Conv2d(num_in, num_mid, kernel_size=3, padding=1, bias=False)\n        self.block1 = nn.Conv2d(num_mid, num_out, kernel_size=3, padding=1, bias=False)\n\n    def forward(self, x):\n        x = nn.functional.relu(self.block0(x), inplace=True)\n        x = nn.functional.relu(self.block1(x), inplace=True)\n        return x\n\n\nclass FPNMobileNet(nn.Module):\n\n    def __init__(self, norm_layer, output_ch=3, num_filters=64, num_filters_fpn=128, pretrained=True):\n        super().__init__()\n\n        # Feature Pyramid Network (FPN) with four feature maps of resolutions\n        # 1/4, 1/8, 1/16, 1/32 and `num_filters` filters for all feature maps.\n\n        self.fpn = FPN(num_filters=num_filters_fpn, norm_layer = norm_layer, pretrained=pretrained)\n\n        # The segmentation heads on top of the FPN\n\n        self.head1 = FPNHead(num_filters_fpn, num_filters, num_filters)\n        self.head2 = FPNHead(num_filters_fpn, num_filters, num_filters)\n        self.head3 = FPNHead(num_filters_fpn, num_filters, num_filters)\n        self.head4 = FPNHead(num_filters_fpn, num_filters, num_filters)\n\n        self.smooth = nn.Sequential(\n            nn.Conv2d(4 * num_filters, num_filters, kernel_size=3, padding=1),\n            norm_layer(num_filters),\n            nn.ReLU(),\n        )\n\n        self.smooth2 = nn.Sequential(\n            nn.Conv2d(num_filters, num_filters // 2, kernel_size=3, padding=1),\n            norm_layer(num_filters // 2),\n            nn.ReLU(),\n        )\n\n        self.final = nn.Conv2d(num_filters // 2, output_ch, kernel_size=3, padding=1)\n\n    def unfreeze(self):\n        self.fpn.unfreeze()\n\n    def forward(self, x):\n\n        map0, map1, map2, map3, map4 = self.fpn(x)\n\n        map4 = nn.functional.upsample(self.head4(map4), scale_factor=8, mode=\"nearest\")\n        map3 = nn.functional.upsample(self.head3(map3), scale_factor=4, mode=\"nearest\")\n        map2 = nn.functional.upsample(self.head2(map2), scale_factor=2, mode=\"nearest\")\n        map1 = nn.functional.upsample(self.head1(map1), scale_factor=1, mode=\"nearest\")\n\n        smoothed = self.smooth(torch.cat([map4, map3, map2, map1], dim=1))\n        smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n        smoothed = self.smooth2(smoothed + map0)\n        smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n\n        final = self.final(smoothed)\n        res = torch.tanh(final) + x\n\n        return torch.clamp(res, min=-1, max=1)\n\n\nclass FPN(nn.Module):\n\n    def __init__(self, norm_layer, num_filters=128, pretrained=True):\n        \"\"\"Creates an `FPN` instance for feature extraction.\n        Args:\n          num_filters: the number of filters in each output pyramid level\n          pretrained: use ImageNet pre-trained backbone feature extractor\n        \"\"\"\n\n        super().__init__()\n        net = MobileNetV2(n_class=1000)\n\n        if pretrained:\n            #Load weights into the project directory\n            state_dict = torch.load('/kaggle/working/GAN_BlurRemoval/models/mobilenet_v2.pth.tar') # add map_location='cpu' if no gpu\n            net.load_state_dict(state_dict)\n        self.features = net.features\n\n        self.enc0 = nn.Sequential(*self.features[0:2])\n        self.enc1 = nn.Sequential(*self.features[2:4])\n        self.enc2 = nn.Sequential(*self.features[4:7])\n        self.enc3 = nn.Sequential(*self.features[7:11])\n        self.enc4 = nn.Sequential(*self.features[11:16])\n\n        self.td1 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n                                 norm_layer(num_filters),\n                                 nn.ReLU(inplace=True))\n        self.td2 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n                                 norm_layer(num_filters),\n                                 nn.ReLU(inplace=True))\n        self.td3 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n                                 norm_layer(num_filters),\n                                 nn.ReLU(inplace=True))\n\n        self.lateral4 = nn.Conv2d(160, num_filters, kernel_size=1, bias=False)\n        self.lateral3 = nn.Conv2d(64, num_filters, kernel_size=1, bias=False)\n        self.lateral2 = nn.Conv2d(32, num_filters, kernel_size=1, bias=False)\n        self.lateral1 = nn.Conv2d(24, num_filters, kernel_size=1, bias=False)\n        self.lateral0 = nn.Conv2d(16, num_filters // 2, kernel_size=1, bias=False)\n\n        for param in self.features.parameters():\n            param.requires_grad = False\n\n    def unfreeze(self):\n        for param in self.features.parameters():\n            param.requires_grad = True\n\n\n    def forward(self, x):\n\n        # Bottom-up pathway, from ResNet\n        enc0 = self.enc0(x)\n\n        enc1 = self.enc1(enc0) # 256\n\n        enc2 = self.enc2(enc1) # 512\n\n        enc3 = self.enc3(enc2) # 1024\n\n        enc4 = self.enc4(enc3) # 2048\n\n        # Lateral connections\n\n        lateral4 = self.lateral4(enc4)\n        lateral3 = self.lateral3(enc3)\n        lateral2 = self.lateral2(enc2)\n        lateral1 = self.lateral1(enc1)\n        lateral0 = self.lateral0(enc0)\n\n        # Top-down pathway\n        map4 = lateral4\n        map3 = self.td1(lateral3 + nn.functional.upsample(map4, scale_factor=2, mode=\"nearest\"))\n        map2 = self.td2(lateral2 + nn.functional.upsample(map3, scale_factor=2, mode=\"nearest\"))\n        map1 = self.td3(lateral1 + nn.functional.upsample(map2, scale_factor=2, mode=\"nearest\"))\n        return lateral0, map1, map2, map3, map4\n","metadata":{"id":"w9tNNNpKxiNG","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:05:46.269483Z","iopub.execute_input":"2024-11-24T19:05:46.269826Z","iopub.status.idle":"2024-11-24T19:05:46.277415Z","shell.execute_reply.started":"2024-11-24T19:05:46.269793Z","shell.execute_reply":"2024-11-24T19:05:46.276536Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!mkdir /root/\n!mkdir /root/.cache/\n!mkdir /root/.cache/torch/\n!mkdir /root/.cache/torch/checkpoints/\n%cd /root/.cache/torch/checkpoints/\n!gdown --id 1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X","metadata":{"id":"fSJm1AEVLu7a","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:05:56.829093Z","iopub.execute_input":"2024-11-24T19:05:56.829883Z","iopub.status.idle":"2024-11-24T19:06:11.813103Z","shell.execute_reply.started":"2024-11-24T19:05:56.829841Z","shell.execute_reply":"2024-11-24T19:06:11.812023Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory '/root/': File exists\nmkdir: cannot create directory '/root/.cache/': File exists\n/root/.cache/torch/checkpoints\n/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X\nFrom (redirected): https://drive.google.com/uc?id=1y6GeaoWjhqjRjrXuZvCYEQYlblZGkE6X&confirm=t&uuid=4d6a267c-7d78-40d6-b6bd-594577dcf935\nTo: /root/.cache/torch/checkpoints/inceptionresnetv2-520b38e4.pth\n100%|████████████████████████████████████████| 224M/224M [00:05<00:00, 39.9MB/s]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#@title ```[OPTIONAL / ONLY RUN THIS IF YOU HAVE PROBLEMS WITH THE PREVIOUS CELL]``` Testrun to download model file with pretrainedmodels (Download takes around 10 minutes)\n%cd /kaggle/working/\n!wget --no-check-certificate https://raw.githubusercontent.com/xinntao/ESRGAN/master/LR/baboon.png\n%cd /kaggle/working/GAN_BlurRemoval\n!python predict.py /kaggle/working/baboon.png\n\n#%cd /kaggle/working/DeblurGANv2/models\n#!gdown --id 1JhnT4BBeKBBSLqTo6UsJ13HeBXevarrU\n%cd /root/.cache/torch/checkpoints\n!gdown --id 1JhnT4BBeKBBSLqTo6UsJ13HeBXevarrU\n%cd /kaggle/working/GAN_BlurRemoval/models\n!wget --no-check-certificate http://sceneparsing.csail.mit.edu/model/pretrained_resnet/mobilenet_v2.pth.tar","metadata":{"id":"HZwavOot5Hbm","cellView":"form"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#@title Run deblur and copy result go Google Drive\n%cd /kaggle/working/GAN_BlurRemoval\n!python predict.py \"/kaggle/working/drive/My Drive/GAN_BlurRemoval/input.png\"\n!cp /kaggle/working/GAN_BlurRemoval/submit/input.png \"/kaggle/working/drive/My Drive/GAN_BlurRemoval/output.png\"","metadata":{"id":"C-rlVgQVv4lz","cellView":"form"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchsummary\n\n# Run deblurring\n%cd /kaggle/working/GAN_BlurRemoval\n!python predict.py \"/kaggle/input/input-png/input.jpeg\"\n\n# Check if the output file exists, remove it, and copy the new one\noutput_path = \"/kaggle/working/GAN_BlurRemoval/submit/input.jpeg\"\ndestination_path = \"/kaggle/working/output.jpeg\"\n\nimport os\nif os.path.exists(destination_path):\n    os.remove(destination_path)  # Remove the existing output file\n    print(f\"Existing file at '{destination_path}' has been removed.\")\n\nif os.path.exists(output_path):\n    !cp {output_path} {destination_path}\n    print(f\"Deblurred image saved as '{destination_path}'\")\nelse:\n    print(f\"Output file '{output_path}' not found. Check the deblurring process for errors.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T19:10:14.484279Z","iopub.execute_input":"2024-11-24T19:10:14.485077Z","iopub.status.idle":"2024-11-24T19:10:31.362282Z","shell.execute_reply.started":"2024-11-24T19:10:14.485043Z","shell.execute_reply":"2024-11-24T19:10:31.361304Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n/kaggle/working/Colab-DeblurGANv2\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load('/kaggle/working/Colab-DeblurGANv2/models/mobilenet_v2.pth.tar') # add map_location='cpu' if no gpu\n/kaggle/working/Colab-DeblurGANv2/predict.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(weights_path)['model'])\n  0%|                                                     | 0/1 [00:00<?, ?it/s][ WARN:0@4.649] global loadsave.cpp:241 findDecoder imread_(''): can't open/read file: check file path/integrity\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:143: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map3 = self.td1(lateral3 + nn.functional.upsample(map4, scale_factor=2, mode=\"nearest\"))\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:144: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map2 = self.td2(lateral2 + nn.functional.upsample(map3, scale_factor=2, mode=\"nearest\"))\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:145: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map1 = self.td3(lateral1 + nn.functional.upsample(map2, scale_factor=2, mode=\"nearest\"))\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:56: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map4 = nn.functional.upsample(self.head4(map4), scale_factor=8, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:57: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map3 = nn.functional.upsample(self.head3(map3), scale_factor=4, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:58: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map2 = nn.functional.upsample(self.head2(map2), scale_factor=2, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:59: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  map1 = nn.functional.upsample(self.head1(map1), scale_factor=1, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:62: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n/kaggle/working/Colab-DeblurGANv2/models/fpn_mobilenet.py:64: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n  smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\nDeblurred image saved as '/kaggle/working/output.jpeg'\n","output_type":"stream"}],"execution_count":20}]}